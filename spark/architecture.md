# Spark 架构(architecture)

Spark遵循主从架构。它的集群由一个主服务器和多个从服务器组成。

Spark架构依赖于两个抽象：

- 弹性分布式数据集(RDD)
- 有向无环图(DAG)

## 弹性分布式数据集(RDD)

弹性分布式数据集是可以存储在工作节点上的内存中的数据项组。

- **弹性**：失败时恢复数据。
- **分布式**：数据分布在不同的节点之间。
- **数据集**：数据组。

稍后将详细了解RDD。

## 有向无环图(DAG)

有向无环图是一种有限的直接图，它对数据执行一系列计算。每个节点都是RDD分区，边缘是数据顶部的转换。

下面来了解Spark架构。

![Spark架构](./images/architecture.png)

#### 驱动程序

驱动程序是一个运行应用程序，由`main()`函数并创建`SparkContext`对象的进程。`SparkContext`的目的是协调spark应用程序，作为集群上的独立进程集运行。

要在群集上运行，`SparkContext`将连接到不同类型的群集管理器，然后执行以下任务： 

- 它在集群中的节点上获取执行程序。
- 它将应用程序代码发送给执行程序。这里，应用程序代码可以通过传递给`SparkContext`的JAR或Python文件来定义。
- 最后，`SparkContext`将任务发送给执行程序以运行。

#### 集群管理器

集群管理器的作用是跨应用程序分配资源。Spark能够在大量集群上运行。
它由各种类型的集群管理器组成，例如：Hadoop YARN，Apache Mesos和Standalone Scheduler。
这里，独立调度程序是一个独立的Spark集群管理器，便于在一组空机器上安装Spark。

#### 工作节点

- 工作节点是从节点
- 它的作用是在集群中运行应用程序代码。

#### 执行程序

- 执行程序是为工作节点上的应用程序启动的进程。
- 它运行任务并将数据保存在内存或磁盘存储中。
- 它将数据读写到外部源。
- 每个应用程序都包含其执行者。

#### 任务

- 任务被发送给一个执行程序的工作单位。