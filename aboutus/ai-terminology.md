# 人工智能术语表

1. 模型（model）：计算机层面的认知

2. 学习算法（learning algorithm），从数据中产生模型的方法

3. 数据集（data set）：一组记录的合集

4. 示例（instance）：对于某个对象的描述

5. 样本（sample）：也叫示例

6. 属性（attribute）：对象的某方面表现或特征

7. 特征（feature）：同属性

8. 属性值（attribute value）：属性上的取值

9. 属性空间（attribute space）：属性张成的空间

10. 样本空间/输入空间（samplespace）：同属性空间

11. 特征向量（feature vector）：在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量

12. 维数（dimensionality）：描述样本参数的个数（也就是空间是几维的）

13. 学习（learning）/训练（training）：从数据中学得模型

14. 训练数据（training data）：训练过程中用到的数据

15. 训练样本（training sample）:训练用到的每个样本

16. 训练集（training set）：训练样本组成的集合

17. 假设（hypothesis）：学习模型对应了关于数据的某种潜在规则

18. 真相（ground-truth）:真正存在的潜在规律

19. 学习器（learner）：模型的另一种叫法，把学习算法在给定数据和参数空间的实例化

20. 预测（prediction）：判断一个东西的属性

21. 标记（label）：关于示例的结果信息，比如我是一个“好人”。

22. 样例（example）：拥有标记的示例

23. 标记空间/输出空间（label space）：所有标记的集合

24. 分类（classification）：预测是离散值，比如把人分为好人和坏人之类的学习任务

25. 回归（regression）：预测值是连续值，比如你的好人程度达到了0.9，0.6之类的

26. 二分类（binary classification）：只涉及两个类别的分类任务

27. 正类（positive class）：二分类里的一个

28. 反类（negative class）：二分类里的另外一个

29. 多分类（multi-class classification）：涉及多个类别的分类

30. 测试（testing）：学习到模型之后对样本进行预测的过程

31. 测试样本（testing sample）：被预测的样本

32. 聚类（clustering）：把训练集中的对象分为若干组

33. 簇（cluster）：每一个组叫簇

34. 监督学习（supervised learning）：典范--分类和回归

35. 无监督学习（unsupervised learning）：典范--聚类

36. 未见示例（unseen instance）：“新样本“，没训练过的样本

37. 泛化（generalization）能力：学得的模型适用于新样本的能力

38. 分布（distribution）：样本空间的全体样本服从的一种规律

39. 独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。

40. 训练集（Training set） —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。

41. 验证集（validation set） —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比 考研之前做的模拟考试。

42. 测试集（Test set） —— 测试训练好的模型的分辨能力。类比 考研。这次真的是一考定终身。

43. 欠拟合（Underfitting）：模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。

44. 过拟合（Overfitting）：模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，做课后题全都做对了，超纲题也都认为是考试必考题目，上了考场还是啥都不会。通俗来说，欠拟合和过拟合都可以用一句话来说，欠拟合就是：“你太天真了！”，过拟合就是：“你想太多了！”。

45. 正确率 —— 提取出的正确信息条数 / 提取出的信息条数

46. 召回率 —— 提取出的正确信息条数 / 样本中的信息条数

47. F 值 —— 正确率 *召回率* 2 / （正确率 + 召回率）（F值即为正确率和召回率的调和平均值）举个例子如下：

    > 某池塘有 1400 条鲤鱼，300 只虾，300 只乌龟。现在以捕鲤鱼为目的。  
    >
    > 撒了一张网，逮住了 700 条鲤鱼，200 只 虾， 100 只乌龟。那么这些指标分别如下： 正确率 = 700 / (700 + 200 + 100) = 70% 召回率 = 700 / 1400 = 50% F 值 = 70% *50%* 2 / (70% + 50%) = 58.3%

48. 分类问题 —— 说白了就是将一些未知类别的数据分到现在已知的类别中去。比如，根据你的一些信息，判断你是高富帅，还是穷屌丝。评判分类效果好坏的三个指标就是上面介绍的三个指标：正确率，召回率，F值。

49. 回归问题 —— 对数值型连续随机变量进行预测和建模的监督学习算法。回归往往会通过计算 误差（Error）来确定模型的精确性。

50. 聚类问题 —— 聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。聚类问题的标准一般基于距离：簇内距离（Intra-cluster Distance） 和 簇间距离（Inter-cluster Distance） 。簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。一般的，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。

51. 特征选择 —— 也叫特征子集选择（FSS，Feature Subset Selection）。是指从已有的 M 个特征（Feature）中选择 N 个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程，是提高算法性能的一个重要手段，也是模式识别中关键的数据预处理步骤。

52. 特征提取 —— 特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点，连续的曲线或者连续的区域。

53. Learning rate —— 学习率，通俗地理解，可以理解为步长，步子大了，很容易错过最佳结果。就是本来目标尽在咫尺，可是因为我迈的步子很大，却一下子走过了。步子小了呢，就是同样的距离，我却要走很多很多步，这样导致训练的耗时费力还不讨好。