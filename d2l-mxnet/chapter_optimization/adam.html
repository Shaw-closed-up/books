<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="/static/img/favicon.png" rel="icon" type="image/png">

    <!-- Theme CSS -->
    <link href="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/css/theme.css" rel="stylesheet" type="text/css"/>
    <link href="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/css/style.css" rel="stylesheet" type="text/css"/>
    <title>Adam算法 - FreeAIHub</title>
  
    <style>
      #top_bar {
          /* background-color: #6e84a3;
          color: white;
          font: bold 12px Helvetica;
          padding: 6px 5px 4px 5px;
          border-bottom: 1px outset; */
      }
      #status {
          text-align: center;
      }
      #sendCtrlAltDelButton {
          position: fixed;
          top: 0px;
          right: 0px;
          border: 1px outset;
          padding: 5px 5px 4px 5px;
          cursor: pointer;
      }

      #screen {
          /* flex: 1;
          overflow: hidden; */
      }

  </style>

  </head>
  <body class="bg-light" style="padding-top: 84px;">
      <header class="navbar navbar-expand navbar-dark flex-column flex-md-row bd-navbar text-center">
      <a class="navbar-brand mr-0 mr-md-2" aria-label="引导程序" href="/">
        <img src="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/images/freeaihub.svg" width="60%" alt="freeai logo">
      </a>
      <ul class="navbar-nav ml-md-auto">
        <li class="nav-item">
          <a href="/" class="nav-link pl-2 pr-1 mx-1 py-3 my-n2">首页</a>
        </li>
        <li class="nav-item">
          <a href="/" class="nav-link pl-2 pr-1 mx-1 py-3 my-n2">课程页面</a>
        </li>
      </ul>
    </header>



    <!-- BREADCRUMB
    ================================================== -->
    <nav class="d-lg-none bg-gray-800">
      <div class="container-fluid">
        <div class="row align-items-center">
          <div class="col">
          </div>
          <div class="col-auto">
            <!-- Toggler -->
            <div class="navbar-dark">
              <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#sidenavCollapse" aria-controls="sidenavCollapse" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
              </button>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </nav>

    <!-- CONTENT
    ================================================== -->
    <section style="overflow: hidden;">
      <div class="container-fluid">
        <div class="row">

          <div class="col-12 col-lg-2 col-xl-2 px-lg-0 border-bottom border-bottom-lg-0 border-right-lg border-gray-300 sidenav sidenav-left">     
            <div class="collapse d-lg-block" id="sidenavCollapse">
              <div class="px-lg-5">
                <ul class="nav side-left">
                  
                </ul>  

              </div>
            </div>


          </div>

          <div class="entry-cellcontent col-10 col-lg-10 col-xl-10 offset-lg-2 offset-xl-2">
          <h1>Adam算法</h1>
<p>Adam算法在RMSProp算法基础上对小批量随机梯度也做了指数加权移动平均 [1]。下面我们来介绍这个算法。</p>
<h2>算法</h2>
<p>Adam算法使用了动量变量$\boldsymbol{v}_t$和RMSProp算法中小批量随机梯度按元素平方的指数加权移动平均变量$\boldsymbol{s}_t$，并在时间步0将它们中每个元素初始化为0。给定超参数$0 \leq \beta_1 &lt; 1$（算法作者建议设为0.9），时间步$t$的动量变量$\boldsymbol{v}_t$即小批量随机梯度$\boldsymbol{g}_t$的指数加权移动平均：</p>
<p>$$\boldsymbol{v}<em>t \leftarrow \beta_1 \boldsymbol{v}</em>{t-1} + (1 - \beta_1) \boldsymbol{g}_t. $$</p>
<p>和RMSProp算法中一样，给定超参数$0 \leq \beta_2 &lt; 1$（算法作者建议设为0.999），
将小批量随机梯度按元素平方后的项$\boldsymbol{g}_t \odot \boldsymbol{g}_t$做指数加权移动平均得到$\boldsymbol{s}_t$：</p>
<p>$$\boldsymbol{s}<em>t \leftarrow \beta_2 \boldsymbol{s}</em>{t-1} + (1 - \beta_2) \boldsymbol{g}_t \odot \boldsymbol{g}_t. $$</p>
<p>由于我们将$\boldsymbol{v}<em>0$和$\boldsymbol{s}_0$中的元素都初始化为0，
在时间步$t$我们得到$\boldsymbol{v}_t =  (1-\beta_1) \sum</em>{i=1}^t \beta_1^{t-i} \boldsymbol{g}<em>i$。将过去各时间步小批量随机梯度的权值相加，得到 $(1-\beta_1) \sum</em>{i=1}^t \beta_1^{t-i} = 1 - \beta_1^t$。需要注意的是，当$t$较小时，过去各时间步小批量随机梯度权值之和会较小。例如，当$\beta_1 = 0.9$时，$\boldsymbol{v}_1 = 0.1\boldsymbol{g}_1$。为了消除这样的影响，对于任意时间步$t$，我们可以将$\boldsymbol{v}_t$再除以$1 - \beta_1^t$，从而使过去各时间步小批量随机梯度权值之和为1。这也叫作偏差修正。在Adam算法中，我们对变量$\boldsymbol{v}_t$和$\boldsymbol{s}_t$均作偏差修正：</p>
<p>$$\hat{\boldsymbol{v}}_t \leftarrow \frac{\boldsymbol{v}_t}{1 - \beta_1^t}, $$</p>
<p>$$\hat{\boldsymbol{s}}_t \leftarrow \frac{\boldsymbol{s}_t}{1 - \beta_2^t}. $$</p>
<p>接下来，Adam算法使用以上偏差修正后的变量$\hat{\boldsymbol{v}}_t$和$\hat{\boldsymbol{s}}_t$，将模型参数中每个元素的学习率通过按元素运算重新调整：</p>
<p>$$\boldsymbol{g}_t' \leftarrow \frac{\eta \hat{\boldsymbol{v}}_t}{\sqrt{\hat{\boldsymbol{s}}_t} + \epsilon},$$</p>
<p>其中$\eta$是学习率，$\epsilon$是为了维持数值稳定性而添加的常数，如$10^{-8}$。和AdaGrad算法、RMSProp算法以及AdaDelta算法一样，目标函数自变量中每个元素都分别拥有自己的学习率。最后，使用$\boldsymbol{g}_t'$迭代自变量：</p>
<p>$$\boldsymbol{x}<em>t \leftarrow \boldsymbol{x}</em>{t-1} - \boldsymbol{g}_t'. $$</p>
<h2>从零开始实现</h2>
<p>我们按照Adam算法中的公式实现该算法。其中时间步$t$通过<code>hyperparams</code>参数传入<code>adam</code>函数。</p>
<p>```{.python .input  n=2}
%matplotlib inline
import d2lzh as d2l
from mxnet import nd</p>
<p>features, labels = d2l.get_data_ch7()</p>
<p>def init_adam_states():
    v_w, v_b = nd.zeros((features.shape[1], 1)), nd.zeros(1)
    s_w, s_b = nd.zeros((features.shape[1], 1)), nd.zeros(1)
    return ((v_w, s_w), (v_b, s_b))</p>
<p>def adam(params, states, hyperparams):
    beta1, beta2, eps = 0.9, 0.999, 1e-6
    for p, (v, s) in zip(params, states):
        v[:] = beta1 * v + (1 - beta1) * p.grad
        s[:] = beta2 * s + (1 - beta2) * p.grad.square()
        v_bias_corr = v / (1 - beta1 <strong> hyperparams['t'])
        s_bias_corr = s / (1 - beta2 </strong> hyperparams['t'])
        p[:] -= hyperparams['lr'] * v_bias_corr / (s_bias_corr.sqrt() + eps)
    hyperparams['t'] += 1</p>
<pre><code>
使用学习率为0.01的Adam算法来训练模型。

```{.python .input  n=5}
d2l.train_ch7(adam, init_adam_states(), {'lr': 0.01, 't': 1}, features,
              labels)
</code></pre>

<h2>简洁实现</h2>
<p>通过名称为“adam”的<code>Trainer</code>实例，我们便可使用Gluon提供的Adam算法。</p>
<p><code>{.python .input  n=11}
d2l.train_gluon_ch7('adam', {'learning_rate': 0.01}, features, labels)</code></p>
<h2>小结</h2>
<ul>
<li>Adam算法在RMSProp算法的基础上对小批量随机梯度也做了指数加权移动平均。</li>
<li>Adam算法使用了偏差修正。</li>
</ul>
<h2>练习</h2>
<ul>
<li>调节学习率，观察并分析实验结果。</li>
<li>有人说Adam算法是RMSProp算法与动量法的结合。想一想，这是为什么？</li>
</ul>
<h2>参考文献</h2>
<p>[1] Kingma, D. P., &amp; Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.</p>
<h2>扫码直达<a href="https://discuss.gluon.ai/t/topic/2279">讨论区</a></h2>
<p><img alt="" src="../img/qr_adam.svg" /></p>
          </div>
          <backend type='k'></backend>
          <code class=gatsby-kernelname data-language=python></code>
        </div> <!-- / .row -->
      </div>
      
    </section>

    <!-- JAVASCRIPT
    ================================================== -->
    <!-- Libs JS -->
    <script src="https://landkit.goodthemes.co/assets/libs/jquery/dist/jquery.min.js"></script>
    <script src="https://landkit.goodthemes.co/assets/libs/bootstrap/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Theme JS -->
    <script src="https://landkit.goodthemes.co/assets/js/theme.min.js"></script>
    <script src="https://cdn.freeaihub.com/asset/js/cell.js"></script>
          
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </body>
</html>