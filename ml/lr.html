<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="/static/img/favicon.png" rel="icon" type="image/png">

    <!-- Theme CSS -->
    <link href="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/css/theme.css" rel="stylesheet" type="text/css"/>
    <link href="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/css/style.css" rel="stylesheet" type="text/css"/>
    <title>线性回归 - FreeAIHub</title>
  
    <style>
      #top_bar {
          /* background-color: #6e84a3;
          color: white;
          font: bold 12px Helvetica;
          padding: 6px 5px 4px 5px;
          border-bottom: 1px outset; */
      }
      #status {
          text-align: center;
      }
      #sendCtrlAltDelButton {
          position: fixed;
          top: 0px;
          right: 0px;
          border: 1px outset;
          padding: 5px 5px 4px 5px;
          cursor: pointer;
      }

      #screen {
          /* flex: 1;
          overflow: hidden; */
      }

  </style>

  </head>
  <body class="bg-light" style="padding-top: 84px;">
      <header class="navbar navbar-expand navbar-dark flex-column flex-md-row bd-navbar text-center">
      <a class="navbar-brand mr-0 mr-md-2" aria-label="引导程序" href="/">
        <img src="https://freeaihub.oss-cn-beijing.aliyuncs.com/asset/images/freeaihub.svg" width="60%" alt="freeai logo">
      </a>
      <ul class="navbar-nav ml-md-auto">
        <li class="nav-item">
          <a href="/" class="nav-link pl-2 pr-1 mx-1 py-3 my-n2">首页</a>
        </li>
        <li class="nav-item">
          <a href="/" class="nav-link pl-2 pr-1 mx-1 py-3 my-n2">课程页面</a>
        </li>
      </ul>
    </header>



    <!-- BREADCRUMB
    ================================================== -->
    <nav class="d-lg-none bg-gray-800">
      <div class="container-fluid">
        <div class="row align-items-center">
          <div class="col">
          </div>
          <div class="col-auto">
            <!-- Toggler -->
            <div class="navbar-dark">
              <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#sidenavCollapse" aria-controls="sidenavCollapse" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
              </button>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </nav>

    <!-- CONTENT
    ================================================== -->
    <section style="overflow: hidden;">
      <div class="container-fluid">
        <div class="row">

          <div class="col-12 col-lg-2 col-xl-2 px-lg-0 border-bottom border-bottom-lg-0 border-right-lg border-gray-300 sidenav sidenav-left">     
            <div class="collapse d-lg-block" id="sidenavCollapse">
              <div class="px-lg-5">
                <ul class="nav side-left">
                  <li><a href="./index.html"> 如何学习本课程 </a></li>
<li><a href="./intro.html"> 机器学习 简介 </a></li>
<li><a href="./feature-engineering.html"> 机器学习 特征工程 </a></li>
<li><a href="./feature-extraction.html"> 机器学习 特征提取 </a></li>
<li><a href="./feature-preprocessing.html"> 机器学习 特征预处理 </a></li>
<li><a href="./feature_selection.html"> 机器学习 特征选择 </a></li>
<li><a href="./feature_selection.html"> 机器学习 特征选择 </a></li>
<li><a href="./metrics.html"> 机器学习 模型评估 </a></li>
<li><a href="./dataset-split.html"> 机器学习 数据集划分 </a></li>
<li><a href="./dataset-split.html"> 机器学习 数据集划分 </a></li>
<li><a href="./knn.html"> 机器学习算法 K近邻(KNN) </a></li>
<li><a href="./nb.html"> 机器学习算法 朴素贝叶斯 </a></li>
<li><a href="./dt.html"> 机器学习算法 决策树 </a></li>
<li><a href="./rf.html"> 机器学习算法 集成学习-随机森林 </a></li>
<li><a href="./lr.html"> 机器学习算法 线性回归 </a></li>
<li><a href="./logstic.html"> 机器学习算法 逻辑回归 </a></li>
<li><a href="./ridge.html"> 机器学习算法 岭回归 </a></li>
<li><a href="./k-means.html"> 机器学习算法 聚类-KMeans </a></li>
<li><a href="./fitting.html"> 机器学习模型 欠拟合与过拟合 </a></li>
<li><a href="./save-load.html"> 机器学习模型 保存与加载 </a></li>
                </ul>  

              </div>
            </div>


          </div>

          <div class="entry-cellcontent col-10 col-lg-10 col-xl-10 offset-lg-2 offset-xl-2">
          <h1>线性回归</h1>
<h4>回忆一下回归问题的判定是什么？</h4>
<h2>线性回归的原理</h2>
<h2>线性回归应用场景</h2>
<ul>
<li>房价预测</li>
<li>销售额度预测</li>
<li>金融：贷款额度预测、利用线性回归以及系数分析因子</li>
</ul>
<p><img alt="销售额度" src="./images/销售额度.png" /></p>
<h2>什么是线性回归</h2>
<h4>定义与公式</h4>
<p>线性回归(Linear regression)是利用<strong>回归方程(函数)</strong>对一个或<strong>多个自变量(特征值)和因变量(目标值)之间</strong>关系进行建模的一种分析方式。</p>
<ul>
<li>特点：只有一个自变量的情况称为单变量回归，大于一个自变量情况的叫做多元回归</li>
</ul>
<p><img alt="线性回归公式" src="./images/线性回归公式.png" /></p>
<p>那么怎么理解呢？我们来看几个例子</p>
<ul>
<li><strong>期末成绩：0.7×考试成绩+0.3×平时成绩</strong></li>
<li><strong>房子价格 = 0.02×中心区域的距离 + 0.04×城市一氧化氮浓度 + (-0.12×自住房平均房价) + 0.254×城镇犯罪率</strong></li>
</ul>
<p>上面两个例子，<strong>我们看到特征值与目标值之间建立的一个关系，这个可以理解为回归方程</strong>。</p>
<h4>线性回归的特征与目标的关系分析</h4>
<p>线性回归当中的关系有两种，一种是线性关系，另一种是非线性关系。<strong>在这里我们只能画一个平面更好去理解，所以都用单个特征举例子。</strong></p>
<ul>
<li>线性关系</li>
</ul>
<p><img alt="线性关系图" src="./images/线性关系图.png" /></p>
<p><img alt="多变量线性关系" src="./images/多变量线性关系.png" /></p>
<blockquote>
<p>注释：如果在单特征与目标值的关系呈直线关系，或者两个特征与目标值呈现平面的关系</p>
<p>更高维度的我们不用自己去想，记住这种关系即可</p>
</blockquote>
<ul>
<li>非线性关系</li>
</ul>
<p><img alt="非线性关系" src="./images/非线性关系.png" /></p>
<blockquote>
<p>注释：为什么会这样的关系呢？原因是什么？我们后面 讲解过拟合欠拟合重点介绍</p>
<p>如果是非线性关系，那么回归方程可以理解为：w1x1+w2x2^2+w3x3^2</p>
</blockquote>
<h2>线性回归的损失和优化原理（理解记忆）</h2>
<p><strong>假设刚才的房子例子，真实的数据之间存在这样的关系</strong></p>
<p>$$
真实关系：真实房子价格 = 0.02×中心区域的距离 + 0.04×城市一氧化氮浓度 + (-0.12×自住房平均房价) + 0.254×城镇犯罪率
$$</p>
<p>那么现在呢，我们随意指定一个关系（猜测）</p>
<p>$$
随机指定关系：预测房子价格 = 0.25×中心区域的距离 + 0.14×城市一氧化氮浓度 + 0.42×自住房平均房价 + 0.34×城镇犯罪率
$$</p>
<p>请问这样的话，会发生什么？真实结果与我们预测的结果之间是不是存在一定的误差呢？类似这样样子</p>
<p><img alt="误差" src="./images/误差.png" /></p>
<p>那么存在这个误差，我们将这个误差给衡量出来</p>
<h3>损失函数</h3>
<p>总损失定义为：</p>
<p><img alt="线性回归损失函数" src="./images/线性回归损失函数.png" /></p>
<ul>
<li>y_i为第i个训练样本的真实值</li>
<li>h(x_i)为第i个训练样本特征值组合预测函数</li>
<li>又称最小二乘法</li>
</ul>
<p><strong>如何去减少这个损失，使我们预测的更加准确些？既然存在了这个损失，我们一直说机器学习有自动学习的功能，在线性回归这里更是能够体现。这里可以通过一些优化方法去优化（其实是数学当中的求导功能）回归的总损失！！！</strong></p>
<h2>优化算法</h2>
<p><strong>如何去求模型当中的W，使得损失最小？（目的是找到最小损失对应的W值）</strong></p>
<p>线性回归经常使用的两种优化算法</p>
<ul>
<li>正规方程</li>
</ul>
<p><img alt="正规方程" src="./images/正规方程.png" /></p>
<blockquote>
<p>理解：X为特征值矩阵，y为目标值矩阵。直接求到最好的结果</p>
<p>缺点：当特征过多过复杂时，求解速度太慢并且得不到结果</p>
</blockquote>
<p><img alt="损失行数求解1" src="./images/损失行数求解1.png" /></p>
<ul>
<li><strong>梯度下降(Gradient Descent)</strong></li>
</ul>
<p><img alt="梯度下降公式" src="./images/梯度下降公式.png" /></p>
<blockquote>
<p>理解：α为学习速率，需要手动指定（超参数），α旁边的整体表示方向</p>
<p>沿着这个函数下降的方向找，最后就能找到山谷的最低点，然后更新W值</p>
<p>使用：面对训练数据规模十分庞大的任务 ，能够找到较好的结果</p>
</blockquote>
<p>我们通过两个图更好理解梯度下降的过程</p>
<p><img alt="单变量的梯度下降" src="./images/单变量的梯度下降.png" /></p>
<p><img alt="多变量的梯度下降" src="./images/多变量的梯度下降.png" /></p>
<p><strong>所以有了梯度下降这样一个优化算法，回归就有了"自动学习"的能力</strong></p>
<h3>优化动态图演示</h3>
<p><img alt="线性回归优化动态图" src="./images/线性回归优化动态图.gif" /></p>
<h2>线性回归API</h2>
<ul>
<li>sklearn.linear_model.LinearRegression(fit_intercept=True)</li>
<li>通过正规方程优化</li>
<li>fit_intercept：是否计算偏置</li>
<li>LinearRegression.coef_：回归系数</li>
<li>LinearRegression.intercept_：偏置</li>
<li>sklearn.linear_model.SGDRegressor(loss="squared_loss", fit_intercept=True, learning_rate ='invscaling', eta0=0.01)</li>
<li>SGDRegressor类实现了随机梯度下降学习，它支持不同的<strong>loss函数和正则化惩罚项</strong>来拟合线性回归模型。</li>
<li>loss:损失类型<ul>
<li><strong>loss=”squared_loss”: 普通最小二乘法</strong></li>
</ul>
</li>
<li>fit_intercept：是否计算偏置</li>
<li>learning_rate : string, optional<ul>
<li>学习率填充</li>
<li><strong>'constant': eta = eta0</strong></li>
<li><strong>'optimal': eta = 1.0 / (alpha * (t + t0)) [default]</strong></li>
<li>'invscaling': eta = eta0 / pow(t, power_t)</li>
<li><strong>power_t=0.25:存在父类当中</strong></li>
<li><strong>对于一个常数值的学习率来说，可以使用learning_rate=’constant’ ，并使用eta0来指定学习率。</strong></li>
</ul>
</li>
<li>SGDRegressor.coef_：回归系数</li>
<li>SGDRegressor.intercept_：偏置</li>
</ul>
<blockquote>
<p>sklearn提供给我们两种实现的API， 可以根据选择使用</p>
</blockquote>
<h4>练习： 波士顿房价预测</h4>
<ul>
<li>数据介绍</li>
</ul>
<blockquote>
<p>给定的这些特征，是专家们得出的影响房价的结果属性。我们此阶段不需要自己去探究特征是否有用，只需要使用这些特征。到后面量化很多特征需要我们自己去寻找</p>
</blockquote>
<p><strong> 分析</strong></p>
<p>回归当中的数据大小不一致，是否会导致结果影响较大。所以需要做标准化处理。同时我们对目标值也需要做标准化处理。</p>
<ul>
<li>数据分割与标准化处理</li>
<li>回归预测</li>
<li>线性回归的算法效果评估</li>
</ul>
<p><strong> 回归性能评估</strong></p>
<p>均方误差(Mean Squared Error)$$MSE$$评价机制：</p>
<p>$$
MSE=\frac{1}{m}\sum^m_{n=1}(y^i-\bar y)^2
$$</p>
<p>注：$y_i$为预测值，$\hat y$为真实值</p>
<ul>
<li><code>sklearn.metrics.mean_squared_error(y_true, y_pred)</code></li>
<li>均方误差回归损失</li>
<li>y_true:真实值</li>
<li>y_pred:预测值</li>
<li>return:浮点数结果</li>
</ul>
<pre><code class="python">from sklearn import datasets
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split


#载入数据集
boston = datasets.load_boston()


#先用key方法查看数据集
print(boston.keys())


#查看feature_names
print(boston['feature_names'])


#这里的data有13个维度，target就是我们要预测的房价，接下来再查看feature_names
print(boston['feature_names'])

#其中'RM'列就是我们需要的房间数，接下为了方便处理，我们将其转为DataFrame类型，并进行数据划分得到训练集和测试集

data = pd.DataFrame(boston['data'],columns=boston['feature_names'])
x = pd.DataFrame(data['RM'],columns=['RM'])
y = pd.DataFrame(boston['target'],columns=['target'])
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33, random_state=42)

#接下来训练线性回归模型，并进行预测

lr = LinearRegression()
lr.fit(x_train,y_train)
y_pre = lr.predict(x_test)
</code></pre>

<pre><code class="python">#模型评价的好坏
#我们将从以下的均方误差(MSE)，均方根误差(RMSE)，平均绝对误差(MAE)，R Squared
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error 
from sklearn.metrics import mean_absolute_error 


print(r2_score(y_test,y_pre))
print(mean_absolute_error(y_test,y_pre))
print(mean_squared_error(y_test,y_pre))
</code></pre>

<pre><code class="python">#可视化
%matplotlib inline
plt.plot(y_test,label='real')
plt.plot(y_lr,label='lr')
plt.legend()
plt.show()
</code></pre>

<p><strong>线性回归与岭回归，lasso回归的比较</strong></p>
<pre><code class="python">from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.datasets import load_boston
import matplotlib.pyplot as plt

boston=load_boston()
data = boston.data
target = boston.target

x_train = data[:450]
y_train = target[:450]
x_test = data[450:]
y_test = target[450:]

lr = LinearRegression()
rr = Ridge()
lasso = Lasso()

lr.fit(x_train,y_train)
rr.fit(x_train,y_train)
lasso.fit(x_train,y_train)

y_lr = lr.predict(x_test)
y_rr = rr.predict(x_test)
y_lasso = lasso.predict(x_test)

plt.plot(y_test,label='real')
plt.plot(y_lr,label='lr')
plt.plot(y_rr,label='rr')
plt.plot(y_lasso,label='lasso')
plt.legend()
plt.show()
</code></pre>

<h3>正规方程和梯度下降对比</h3>
<p><img alt="正规方程和梯度下降对比" src="./images/正规方程和梯度下降对比.png" /></p>
<ul>
<li>文字对比</li>
</ul>
<table>
<thead>
<tr>
<th align="center">梯度下降</th>
<th align="center">正规方程</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">需要选择学习率</td>
<td align="center">不需要</td>
</tr>
<tr>
<td align="center">需要迭代求解</td>
<td align="center">一次运算得出</td>
</tr>
<tr>
<td align="center">特征数量较大可以使用</td>
<td align="center">需要计算方程，时间复杂度高O(n3)</td>
</tr>
</tbody>
</table>
<ul>
<li>选择：</li>
<li>小规模数据：<ul>
<li><strong>LinearRegression(不能解决拟合问题)</strong></li>
<li>岭回归</li>
</ul>
</li>
<li>大规模数据：<code>SGDRegressor</code></li>
</ul>
<h2>拓展-关于优化方法GD、SGD、SAG</h2>
<h3>GD</h3>
<p><strong>梯度下降(Gradient Descent)，原始的梯度下降法需要计算所有样本的值才能够得出梯度，计算量大，所以后面才有会一系列的改进。</strong></p>
<h3>SGD</h3>
<p><strong>随机梯度下降(Stochastic gradient descent)是一个优化方法。它在一次迭代时只考虑一个训练样本。</strong></p>
<ul>
<li>SGD的优点是：</li>
<li>高效</li>
<li>容易实现</li>
<li>SGD的缺点是：</li>
<li>SGD需要许多超参数：比如正则项参数、迭代数。</li>
<li>SGD对于特征标准化是敏感的。</li>
</ul>
<h3>SAG</h3>
<p>随机平均梯度法(Stochasitc Average Gradient)，由于收敛的速度太慢，有人提出SAG等基于梯度下降的算法</p>
<blockquote>
<p>Scikit-learn：SGDRegressor、岭回归、逻辑回归等当中都会有SAG优化</p>
</blockquote>
<h2>总结</h2>
<ul>
<li>线性回归的损失函数-均方误差</li>
<li>线性回归的优化方法</li>
<li>正规方程</li>
<li>梯度下降</li>
<li>线性回归的性能衡量方法-均方误差</li>
<li>sklearn的<code>SGDRegressor</code> API 参数</li>
</ul>
<h2>学习目标</h2>
<ul>
<li>记忆线性回归的原理过程</li>
<li>应用LinearRegression或SGDRegressor实现回归预测</li>
<li>
<p>记忆回归算法的评估标准及其公式</p>
</li>
<li>
<p>波士顿房价预测</p>
</li>
</ul>
          </div>
          <backend type='k'></backend>
          <code class=gatsby-kernelname data-language=python></code>
        </div> <!-- / .row -->
      </div>
      
    </section>

    <!-- JAVASCRIPT
    ================================================== -->
    <!-- Libs JS -->
    <script src="https://landkit.goodthemes.co/assets/libs/jquery/dist/jquery.min.js"></script>
    <script src="https://landkit.goodthemes.co/assets/libs/bootstrap/dist/js/bootstrap.bundle.min.js"></script>

    <!-- Theme JS -->
    <script src="https://landkit.goodthemes.co/assets/js/theme.min.js"></script>
    <script src="https://cdn.freeaihub.com/asset/js/cell.js"></script>
          
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </body>
</html>